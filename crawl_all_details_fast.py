import time
import json
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

# 스레드 안전을 위한 락
print_lock = Lock()
update_lock = Lock()

def crawl_shop_detail(url, driver):
    """상점 상세 페이지 완전 크롤링"""
    try:
        driver.get(url)
        time.sleep(1.5)  # 페이지 로딩 대기 (병렬 처리 시 더 짧게)
        
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        all_text = soup.get_text()
        
        detail = {
            'phone': '',
            'hours': '',
            'description': '',
            'address_detail': '',
            'price_info': '',
            'payment_methods': []
        }
        
        # 전화번호 추출
        phone_patterns = [
            r'010[-.\s]?\d{4}[-.\s]?\d{4}',  # 010-xxxx-xxxx
            r'\+82[-.\s]?10[-.\s]?\d{4}[-.\s]?\d{4}',  # +82-10-xxxx-xxxx
            r'02[-.\s]?\d{3,4}[-.\s]?\d{4}',  # 02-xxx-xxxx
            r'0\d{1,2}[-.\s]?\d{3,4}[-.\s]?\d{4}',  # 기타 지역번호
        ]
        
        for pattern in phone_patterns:
            phone_match = re.search(pattern, all_text)
            if phone_match:
                phone = phone_match.group(0).replace(' ', '').replace('.', '-')
                if not re.match(r'^\d{1,2}-\d{1,2}$', phone):
                    if phone.startswith('+82'):
                        phone = phone.replace('+82', '0').replace('-', '')
                        if len(phone) == 11 and phone.startswith('010'):
                            phone = f"{phone[:3]}-{phone[3:7]}-{phone[7:]}"
                    detail['phone'] = phone
                    break
        
        # 페이지의 모든 텍스트를 줄 단위로 분석
        lines = [line.strip() for line in all_text.split('\n') if line.strip()]
        
        # 매장 소개 정보 찾기
        description_parts = []
        found_intro = False
        
        for i, line in enumerate(lines):
            # 영업시간
            if any(kw in line for kw in ['영업시간', '운영시간', 'Hours', '오픈']):
                detail['hours'] = line
                if i + 1 < len(lines):
                    detail['hours'] += ' ' + lines[i + 1]
            
            # 매장 소개 시작점 찾기
            if any(kw in line for kw in ['오리불고기', '오리주물럭', '오리탕', '점심특선', '쌈밥', '신선한야채', '건강밥상', '결제', '베리']):
                found_intro = True
            
            # 매장 소개 정보 수집
            if found_intro:
                if any(kw in line for kw in ['VERY 단가', 'VERY단가', '결제비율', '결제 비율']):
                    if 'VERY 단가' in line or 'VERY단가' in line:
                        if i + 1 < len(lines):
                            detail['price_info'] = lines[i + 1]
                    if '결제비율' in line or '결제 비율' in line:
                        if i + 1 < len(lines):
                            detail['payment_methods'].append(lines[i + 1])
                    break
                
                skip_keywords = ['KR', 'verypay', 'verychain', 'verychat', 'veryads', 'VeryPay', 'Logo']
                if line and len(line) > 1:
                    if not any(skip in line for skip in skip_keywords):
                        if line not in description_parts:
                            description_parts.append(line)
        
        if description_parts:
            detail['description'] = '\n'.join(description_parts)
        
        if not detail['description']:
            meta_desc = soup.find('meta', attrs={'name': 'description'})
            if meta_desc:
                detail['description'] = meta_desc.get('content', '')
        
        return detail
        
    except Exception as e:
        with print_lock:
            print(f"  [오류] {url}: {e}")
        return {
            'phone': '',
            'hours': '',
            'description': '',
            'address_detail': '',
            'price_info': '',
            'payment_methods': []
        }

def create_driver():
    """브라우저 드라이버 생성"""
    chrome_options = Options()
    chrome_options.add_argument("--headless")  # 헤드리스 모드로 더 빠르게
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--blink-settings=imagesEnabled=false")  # 이미지 로딩 비활성화
    prefs = {"profile.managed_default_content_settings.images": 2}
    chrome_options.add_experimental_option("prefs", prefs)
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
    return driver

def process_shop(shop, original_index, display_index, total):
    """단일 매장 처리"""
    driver = create_driver()
    try:
        if not shop.get('link'):
            return None, original_index
        
        detail = crawl_shop_detail(shop['link'], driver)
        
        with print_lock:
            print(f"[{display_index}/{total}] {shop.get('name', 'Unknown')[:30]}... 완료")
        
        return (shop, detail), original_index
    finally:
        driver.quit()

# 메인 실행
if __name__ == '__main__':
    # 기존 데이터 로드
    with open('public/data/shops.json', 'r', encoding='utf-8') as f:
        shops = json.load(f)
    
    # 링크가 있는 매장만 필터링
    shops_with_links = [(shop, i) for i, shop in enumerate(shops) if shop.get('link')]
    
    print(f"총 {len(shops_with_links)}개의 매장 상세 정보 크롤링 시작...")
    print(f"병렬 처리: 최대 5개 동시 실행 (약 {len(shops_with_links) * 1.5 / 5 / 60:.1f}분 예상)")
    print("=" * 50)
    
    start_time = time.time()
    updated_count = 0
    
    # 병렬 처리 (최대 5개 동시 실행)
    with ThreadPoolExecutor(max_workers=5) as executor:
        # 모든 작업 제출
        future_to_shop = {
            executor.submit(process_shop, shop, original_index, display_index+1, len(shops_with_links)): (shop, original_index)
            for display_index, (shop, original_index) in enumerate(shops_with_links)
        }
        
        # 완료된 작업 처리
        for future in as_completed(future_to_shop):
            try:
                result, original_index = future.result()
                if result:
                    shop, detail = result
                    # 기존 데이터에 상세 정보 업데이트
                    with update_lock:
                        shops[original_index].update(detail)
                        updated_count += 1
            except Exception as e:
                with print_lock:
                    print(f"  [오류] 작업 처리 중 오류: {e}")
    
    elapsed_time = time.time() - start_time
    
    print("=" * 50)
    print(f"\n총 {updated_count}개의 매장 상세 정보 크롤링 완료!")
    print(f"소요 시간: {elapsed_time:.1f}초 ({elapsed_time/60:.1f}분)")
    
    # 저장
    with open('public/data/shops.json', 'w', encoding='utf-8') as f:
        json.dump(shops, f, ensure_ascii=False, indent=2)
    
    print("shops.json 저장 완료!")
